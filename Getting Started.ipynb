{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layered Perceptrons\n",
    "MLPs are nearly synonomous with Neural Networks so it makes sense to start discussing CNNs by discussing MLPs. Overall they are just a composition of perceptrons (first formulated by a guy named Rosenblatt back in the 50s/60s) meshed together to receive inputs, outputs, and initialized weights. \n",
    "\n",
    "The key to these tools is finding the optimal weight. That is what training a neural network actually does, is it finds the weights for each of the inputs. To calculate the change in weights we need to deal with a popular algorithm called backpropagation. To understand in depth what is happening, you need to have a bit of calculus in your background, otherwise just trust me when I say it works and skip the next paragraph.\n",
    "\n",
    "The output of a perceptron is the multiplication of the weight and input fed through an activation function. At the end of the network a loss is calculated for the network. Well, to get the necessary change in weights we simply go backwards. We take the derivatives of each of those steps and chain them together using the chain rule:\n",
    "\n",
    "$$\\delta_j(k) = -\\frac{\\partial E(k)}{\\partial e_j(k)}\\frac{\\partial e_j(k)}{\\partial y_j(k)}\\frac{\\partial y_j(k)}{\\partial v_j(k)}$$\n",
    "\n",
    "$$\\delta_j(k) = e_j(k)\\Phi_j'(v_j(k))$$\n",
    "\n",
    "Where $e_j(k)$ is the difference between the output and label and $\\Phi_j'(v_j(k))$ is the derivative of the activation function with the product of the inputs and weights. Finally, we can achieve the necessary change in weights by simply doing the gradient descent rule at each perceptron, or: \n",
    "\n",
    "$$\\Delta w_{ij}(k) = \\alpha \\delta_j(k)y_j(k)$$ \n",
    "\n",
    "with $y_j(k)$ being the inputs and $\\alpha$ being the learning rate. This is briefly described in the function below. And please keep in mind this is for a generic fully connected neural network, not a CNN (yet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(activation, e, labels, alpha, beta):\n",
    "    previous_h1 = 0\n",
    "    previous_in = 0\n",
    "    epoch = e\n",
    "    err = np.zeros((epoch,10))\n",
    "    data = np.asarray(train_image_list)\n",
    "    input_weights = np.random.rand(196, 100) #initialize weights via a random distribution\n",
    "    h1_weights = np.random.rand(100, 10)\n",
    "    for k in range(epoch):\n",
    "        err[k] = 0\n",
    "        for i in range(15000):\n",
    "            \n",
    "            # sample and preprocess \n",
    "            d = data[i,:]\n",
    "            d = np.divide(d,255)\n",
    "            d = np.reshape(d, (1,-1))\n",
    "\n",
    "            # Forward Pass Into Hidden Layer 1\n",
    "            fp1 = activation(np.dot(d, input_weights))\n",
    "\n",
    "            # Forward Pass Into Hidden Layer 2\n",
    "            # fpo = activation(np.dot(fp1, h1_weights)) #enable for sigmoid\n",
    "            fpo = np.dot(fp1, h1_weights) \n",
    "\n",
    "            # ERROR RATE CALCULATION\n",
    "            # Reshape labels to fit error calculation\n",
    "            l = np.reshape(labels[i,:], (1,-1))\n",
    "            err[k] = err[k] + (1.0/2.0) * (np.power((fpo - l), 2.0))\n",
    "\n",
    "            # BACKPROP\n",
    "            deltas_out_layer = (-1) * (l - fpo)\n",
    "            partial_out = np.transpose(fp1) * deltas_out_layer\n",
    "\n",
    "            deltas_h1_layer =  (activation(fp1, derive=True)) * np.dot(deltas_out_layer, np.transpose(h1_weights))\n",
    "            partial_h1 = np.transpose(d) * deltas_h1_layer\n",
    "            \n",
    "            momentum_h1 = (beta * previous_h1) + ((-alpha) * partial_out) \n",
    "            h1_weights = h1_weights + momentum_h1\n",
    "            previous_h1 = momentum_h1\n",
    "\n",
    "            momentum_in = (beta * previous_in) + ((-alpha) * partial_h1)\n",
    "            input_weights = input_weights + momentum_in\n",
    "            previous_in = momentum_in\n",
    "\n",
    "    plt.plot(err[0:24])\n",
    "    plt.ylabel('error')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.show()\n",
    "    return input_weights, h1_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNets/CNNs and Convolutions\n",
    "A CNN is very similar to a standard fully connected neural network, except instead of connecting each output of the previous layer to each perceptron in the next layer, it shares some of them. This is done through convolutions (a concept used earlier in image processing and applied to neural networks). \n",
    "\n",
    "In essence a convolution is a secondary smaller matrix (usually called a kernel, window, or mask) moving across an image to gather information about it. The distance the kernel moves from one calculation to the next is called the **stride**.\n",
    "\n",
    "The entire point of a convolutional neural network is to find the correct values that belong in the kernel matrix, that is what is being optimized in a CNN. These kernel matrices are updated in backpropagation. In doing so, they become pseudo-feature detectors in images and become really good at locating edges, color differentials, etc. For more examples of what standardized kernels can do and look like see [this wiki page](https://en.wikipedia.org/wiki/Kernel_(image_processing))\n",
    "\n",
    "Really quickly, just so we can get going, lets talk about one more term called **transfer learning**. This is basically the idea of taking a pretrained neural network (trained on other datasets etc.) and using those initial weights and features as a starting point for your training. \n",
    "\n",
    "Great, now lets go into [pytorch](https://pytorch.org/)! From the start, we shall a [quick demo of transfer learning](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html) provided by pytorch\n",
    "\n",
    "Convolution Visualization: https://gfycat.com/plasticmenacingdegu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
